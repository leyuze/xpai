---
title: 日志集中以及链路跟踪分析平台ELK
date: 2021-01-25 15:50:36
permalink: /pages/0aa9a6/
categories:
  - 后端
  - 容器化和中间件
tags:
  - Elasticsearch
  - ELK
---
# 搭建ELK环境

## 安装elasticsearch  

### 简介

许多年前，一个刚结婚的名叫shay Banon的失业开发者，跟着他的妻子去了伦敦，他的妻子在那里 学习厨师。为了给他的妻子做一个食谱搜索引擎，他开始使用Lucene的一个早期版本。直接使用 Lucene是很难的，因此Shay开始做一个抽象层，Java开发者使用它可以很简单的给他们的程序添加 搜索功能。他发布了他的第一个开源项目Compass。

后来Shay获得了一份工作，主要是高性能，分布式环境下的内存数据网格。这个对于高性能，实 时，分布式搜索引擎的需求尤为突出，他决定重写Compass,把它变为一个独立的服务并取名 Elasticsearch。

第一^公开版本在2010年2月发布，从此以后，Elasticsearch已经成为了 Github上最活跃的项 目之一，他拥有超过300名contributors（目前736名contributors ）。一家公司已经开始围绕 Elasticsearch提供商业服务，并开发新的特性，但是，Elasticsearch将永远开源并对所有人可 用。

据说，Shay的妻子还在等着她的食谱搜索引擎...0_0!

Elasticsearch是一个开源的搜索引擎，建立在一个全文搜索引擎库Lucene基础之上。Lucene可 以说是当下最先进、高性能、全功能的搜索引擎库，缺点是Lucene的使用非常的复杂。Elasticsearch 也是使用Java编写的，它的内部使用Lucene做索引与搜索，但是它的目的是使全文检索变得简单， 通过隐藏Lucene的复杂性，取而代之的提供一套简单一致的RESTful API。

### 相关链接

官网：

[https://www .elastic .co/cn/downloads/elasticsea rch](https://www.elastic.co/cn/downloads/elasticsearch)

下载：

wget[ https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.5.1-linux-x86 64.tar.gz](https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.5.1-linux-x86_64.tar.gz)

分词器：

[https://github .com/medcl/elasticsea rch-analysis-ik](https://github.com/medcl/elasticsearch-analysis-ik)

### 部署

系统环境：以下课程假设测试机器ip为172.17.0.203

解压：

```
tar xvf elasticsearch-7.5.1-linux-x86_64.tar.gz
```

修改:

config/elasticsearch.yml

```
#主机名，通过hostname命令查询到 cluster.initial_master_nodes : ["主机名"]
network.host: 0.0.0.0 
http.port: 9200 
http.cors.enabled: true 
http.cors.allow-origin: "*"
```

修改文件描述符:

```
vim /etc/sysctl.conf

vm.max_map_count=64000 

sysctl -p
```

启动:

```
#es不允许root用户启动，需要添加新用户身份
#创建elsearch用户组及elsearch用户
groupadd elsearch
useradd elsearch -g elsearch -p elasticsearch
#更改elasticsearch文件夹及内部文件的所属用户及组为elsearch:elsearch
chown -R elsearch:elsearch ./opt/elk/elasticsearch-7.5.1
#切换到elsearch用户再启动
su elsearch
#守护进程运行
./bin/elasticsearch -d
#验证启动进程
ps aux | grep elasticsearch
```

删除用户：

```
 [root@localhost /]# userdel -r 用户名
```



验证:

访问[ http://172.17.0.203:9200](http://172.17.0.203:9200/) ,启动成功

```json
{
  "name" : "iZbp14sp42lwvcxdmqw61zZ",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "VCOf0wUGTMajBPc3Q-KSew",
  "version" : {
    "number" : "7.5.1",
    "build_flavor" : "default",
    "build_type" : "tar",
    "build_hash" : "3ae9ac9a93c95bd0cdc054951cf95d88e1e18d96",
    "build_date" : "2019-12-16T22:57:37.835892Z",
    "build_snapshot" : false,
    "lucene_version" : "8.3.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}
```

### 中文分词器安装

es默认分词器对中文分词非常不友好，需要安装ik分词器

Analyzer: ik_smart , ik_max_word , Tokenizer: ik_smart , ik_max_word

```
wget -c https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.5.1/elasticsearch-analysis-ik-7.5.1.zip
```

在es安装目录下面的plus文件夹下面创建 ik 文件夹 ，将下载的文件解压到此目录

```
mkdir $ES_HOME/plugins/ik
unzip elasticsearch-analysis-ik-7.5.1.zip -d $ES_HOME/plugins/ik
```

安装完成重启es

验证分词器：

POST:[ http：//172.17.0.203:9200/ analyze](http://172.17.0.203:9200/_analyze)

BODY: {"text":"测试分词效果"‘"analyze r": "ik_sma rt"}

指令：curl[ http://localhost:9200/ analyze ](http://localhost:9200/_analyze)-X POST -H 'Content-Type:application/json' -d

'{"text":"test elasticsea rch 测试分词效果"‘"analyze r": "ik_sma rt"}'

```
RESULT："tokens": [
{
"token": "test", "start_offset": 0, "end_offset": 4, "type": "ENGLISH", "position": 0
},
{
"token": "elasticsearch", "start_offset": 5, "end_offset": 18, "type": "ENGLISH", "position": 1
},
{
"token":"测试"， "start_offset": 19, "end_offset": 21， "type": "CN_WORD"， "position": 2
}，
{
"token":"分词"， "start_offset": 21， "end_offset": 23， "type": "CN_WORD"， "position": 3
}，
{
"token":"效果"， "start_offset": 23， "end_offset": 25， "type": "CN_WORD"， "position": 4
}
]
}
```

注意：

Elasticsearch集成analysis ik中文分词器 时出现：

```
Plugin [analysis-ik] was built for Elasticsearch version 6.5.0 but version 6.7.1 is running.....
```

问题原因是：Es 版本和 ik分词器版本不一致。由于我用的Es时最新版本 6.7.1，而ik分词器master编译出来也只是6.5.0

修改 plugin-descriptor.properties 文件

```
elasticsearch.version=你的ES版本号
```

### 安装es-head

我们可以方便的使用curl等客户端工具，通过Restful API对Elasticsea rch进行操作，但也有一些客 户端工具提供对于ElasticSearch更加友好的可视化操作支持，elasticsearch-head就是其中很优秀的代 表。

早期版本的elasticsea rch-head可以直接以插件的方式在Elasticsea rch中进行安装，在 Elasticsea rch 5之后则需要将elasticsea rch-head服务单独运行，并且支持Chr ome的插件方式或者 Docke r容器运行方式。

部署

#采用docker启动

\#查看镜像 

```
docker images | grep elasticsearch-head
```

\#下载镜像

```
docker pull alivv/elasticsearch-head
```

\#启动

```
docker run -d --name eshead -p 9100:9100 alivv/elasticsearch-head
```

验证：

访问910 0端口，并连接es地址:

![](https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/QQ%E6%88%AA%E5%9B%BE20210125174540.png)

## logstash安装

### 简介

Logstash诞生于2009年8有2日，其作者是世界著名的虚拟主机托管商Dr eamHost的运维工程师Jordan Sissel。在2013年，被ElasticSearch公司收购，作为日志收集工具，成为elk的一员。

相关链接

项目主页：

[https://www .elastic .co/cn/downloads/logstash](https://www.elastic.co/cn/downloads/logstash)

下载地址：

wget[ https://a rtifacts .elastic .co/downloads/logstash/logstash-7.5.1 ・ta r.gz](https://artifacts.elastic.co/downloads/logstash/logstash-7.5.1.tar.gz)

### 部署

解压：

```
tar xvf logstash-7.5.1.tar.gz
```

配置：

（案例一）在conf.d目录下新建一个configl .conf文件，用于监听es中的数据内容

```
input {
file {
path => "/root/logs/*.log" start_position => beginning add_field => {"from" => "localfile"} }
}
filter {
} output { elasticsearch {
hosts => "localhost:9200"
index => "mylog"
}
stdout {
}
}
```

验证：

\#生成一条测试日志数据，从es-head验证是否正常采集 

mkdir -p /root/logs/

date >> /root/logs/1.log

（案例二）监听tomcat的日志

进入logstash的bin目录

新建文件 vim logstash1.conf ，写入内容(监听tomcat的日志)：

```
input {
    file {
        path => "/usr/share/tomcat/logs/*.log"
        start_position => beginning
    }
}
filter {
 
}
output {
    elasticsearch {
    hosts => "localhost:9200"
    }
 
}

```

启动logstash：sh logstash -f logstash1.conf  &

如果提示--path.data的问题，则需要指定path.data的路径，随便找个路径就行，

我的是这样启动：

```
sh logstash -f logstash1.conf  --path.data=/opt/elk/logstash-7.5.1/logs &
```

（案例三）logstash配置mysql数据同步到elasticsearch

获取 jdbc mysql 驱动：

wget https://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.46.zip unzip mysql-connector-java-5.1.46.zip

可以把解压后的mysql-connector-java-5.1.46-bin.jar复制到bin目录，方便启动

在bin目录新建配置文件   vim mysql-logstash.cnf ，写入：

```
input {
  jdbc {
    jdbc_driver_library => "mysql-connector-java-5.1.46-bin.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_connection_string => "jdbc:mysql://ip:3306/db_name"
    jdbc_user => "jdbc_user"
    jdbc_password => "jdbc_password"
    schedule => "* * * * *"
    statement => "SELECT * FROM table WHERE 时间字段 >= :sql_last_value"
    use_column_value => true
    tracking_column_type => "timestamp"
    tracking_column => "时间字段"
    last_run_metadata_path => "syncpoint_table"
  }
}
 
 
output {
  elasticsearch {
    hosts => "localhost:9200"
    index => "索引名称"
    document_id => "%{主键字段}"
  }
}

```

需要先把logstash停了，在重启

netstat -ntlp  命令查看端口为9600的进程，

使用命令 sh logstash -f mysql-logstash.cnf --path.data=/opt/elk/logstash-7.5.1/logs &

## kibana安装

![](https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/kibana.jpg)

相关链接

[https://www .elastic .co/cn/downloads/kibana](https://www.elastic.co/cn/downloads/kibana)

[https://artifacts.elastic.co/downloads/kibana/kibana-7.5.1 -linux-x86 64.tar.gz](https://artifacts.elastic.co/downloads/kibana/kibana-7.5.1-linux-x86_64.tar.gz)

安装部署

解压：

```
tar xvf kibana-7.5.1-linux-x86_64.tar.gz
```

配置：

config/kibana.yml

```
server.port:	9102
server.host:	"0.0.0.0"
elasticsearch.hosts: "http://localhost:9200 kibana.index: ".kibana"
```

启动:

\#kibana默认不允许root用户启动，可以加--allow-root选项

```
nohup sh /opt/elk/kibana-7.5.1-linux-x86_64/bin/kibana --allow-root >/opt/logs/kibana.log &
```

验证:

启动成功，数据为空，向es提交一条数据，通过es-head查询，并通过logstash查询类比展示下面logstash搭建完成后，会再次展示通过采集进入的数据。

![](https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/QQ%E6%88%AA%E5%9B%BE20210125180202.png)

## kafka安装

Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeepe r协调 的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等 等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。常用于日志处理场景。

资源

[http://kafka.apache. or g/downloads](http://kafka.apache.org/downloads)

docker 部署

kafka和zk的镜像拉取省略。。。

```
docker run --name zookeeper -v /opt/data/zksingle:/data -p 2181:2181 -e ZOO_LOG4J_PROP="INFO,ROLLINGFILE" -d zookeeper:latest
```

启动kafka

```
docker run -d --name kafka -p 9103:9092 --link zookeeper:zookeeper --env KAFKA_BROKER_ID=100 --env HOST_IP=47.110.229.77 --env KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 --env KAFKA_ADVERTISED_HOST_NAME=47.110.229.77 --env KAFKA_ADVERTISED_PORT=9103 --restart=always --volume /etc/localtime:/etc/localtime wurstmeister/kafka:2.11-0.11.0.3
```



验证

\#使用zk节点数据验证启动情况

```
docker exec -it zookeeper sh
```

\#进入zookeeper后查看节点信息

```
ls /brokers
```

\#进入容器

```
docker exec -it kafka sh

/opt/kafka_2.12-2.2.2/bin
```

\#客户端监听（该步会自动创建topic）

```
./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic demo -- from-beginning
```

\#另起一个终端，验证发送

```
./kafka-console-producer.sh --broker-list localhost:9092 --topic demo
```

5）实例操作

修改logstash从kafka获取，从控制台重新写入一条日志，进kibana查看数据展示情况

```
input { file {

path => "/root/logs/*.log" 

start_position => beginning add_field => {"from" => "localfile"}

}

kafka { bootstrap_servers => ["39.98.133.153:9103"] group_id => "logstash" topics => ["demo"] consumer_threads => 1 decorate_events => true add_field => {"from" => "demo"}

}

} filter {

}

output {

elasticsearch {

hosts => "localhost:9200"

index => "mylog"

}

stdout {

}

}
```

### kafkamanager安装

kafka-manage r是目前最受欢迎的kafka集群管理工具，最早由雅虎开源，用户可以在Web界面执 行一些简单的集群管理操作。具体支持以下内容：

- 管理多个集群

- 轻松检查群集状态（主题，消费者，偏移，代理，副本分发，分区分发）

- 运行首选副本选举

- 使用选项生成分区分配以选择要使用的代理

- 运行分区重新分配（基于生成的分配）

- 使用可选主题配置创建主题（0.8.1.1具有与0.8.2+不同的配置）

- 删除主题（仅支持0.8.2+并记住在代理配置中设置delete.topic.enable = tr ue）

- 主题列表现在指示标记为删除的主题（仅支持0.8.2+）

- 批量生成多个主题的分区分配，并可选择要使用的代理

- 批量运行重新分配多个主题的分区

- 将分区添加到现有主题

- 更新现有主题的配置

资源

[https://github.com/yahoo/kafka-manage r/r eleases](https://github.com/yahoo/kafka-manager/releases)

docke r库里的版本太陈旧，需要从官网下载源码包，编译成二进制包。具体编译过程参考项目主页 下面的Deployment章节。

部署中直接使用打好包的kafka-manager-2.0O2.zip, manage版本为2.0.0.2,配置kafka cluster 最高支持2.2.0，实际验证，可以•操作kafka 2.2.2

3）部署

\#解压

```
unzip kafka-manager-2.0.0.2.zip
```

\#配置文件，修改目录下的conf/application.conf kafka-manager.zkhosts="localhost:2181"

\#启动，指定端口 9104

```
km_home=./kafka-manager-2.0.0.2
```

```
nohup $km_home/bin/kafka-manager -Dconfig.file=$km_home/conf/application.conf - Dhttp.port=9104 > /opt/logs/kibana.log &
```

```
tail -f /opt/logs/kibana.log
```

4功能说明

- cluste r创建与管理

- Br oke rs信息查看

- topic创建与管理

- patte rn 及 r eplica 配置

## Filebeat安装

简介

Filebeat是一个轻量级日志传输Agent，可以•将指定日志转发到Logstash, Elasticsearch、Kafka、 Redis等中。Filebeat占用资源少，而且安装配置也比较简单，支持目前各类主流OS及Docker平台。

![](https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/QQ%E6%88%AA%E5%9B%BE20210125181351.png)

[https://www .elastic .co/cn/p roducts/beats/filebeat](https://www.elastic.co/cn/products/beats/filebeat)

下载：

wget[ https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.5.1-linux-x86 64.tar.gz](https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.5.1-linux-x86_64.tar.gz)

部署

解压：

```
tar zxvf filebeat-7.5.1-linux-x86_64.tar.gz
```

 使用kafka-manage r创建一个filebeat队列

配置 filebeat .yml：

```
filebeat.inputs:

\- type: log

enabled: true

paths:

\- /root/logs/*.log fields:

from: filebeat 

output.kafka:

enabled: true

hosts: ["39.98.133.153:9103"]

topic: filebeat

compression: gzip

processors:

\- drop_fields: fields: ["beat", "input", "source",

"offset","metadata","timestamp","agent","ecs","fields"]

filebeat.config.modules:

path: ${path.config}/modules.d/*.yml

reload.enabled: true

logging.level: info

name: filebeat-server-ip
```

启动：

```
cd /opt/app/elk/filebeat-7.5.1-linux-x86_64

nohup ./filebeat -e -c filebeat.yml >> /opt/logs/filebeat.log &
```

```
tail -f /opt/logs/filebeat.log
```

4）验证

修改logstash，去掉file采集，接收来自filebeat队列的消息。

请注意！这里有一个问题：filebeat默认读取字符后，输出的是json格式，上述codec即让logstash解析

json,但是仍会报错。原因是filebeat里的host.name属性，需要加入filter,合并属性名字：

```
input {

kafka {

bootstrap_servers => ["39.98.133.153:9103"]

group_id => "logstash"

topics => ["filebeat"] consumer_threads => 1 decorate_events => true add_field => {"from" => "filebeat"} codec => "json"

}

}

filter {

mutate {

rename => { "[host][name]" => "host" }

重新录入一条日志信息仅log文件，查看logstash stdout日志，查看kibana是否正常采集入es 附：filebeat输出json格式参考范本

{

"@timestamp": "2019-05-11T07:55:02.127Z", "@metadata": {

"beat": "filebeat", "type": "_doc", "version": "7.5.1", "topic": "app.log"

},

"ecs": { "version": "1.0.0"

},

"log": { "offset": 2661796, "file": {

"path": "/var/log/app.log"

}

},

"message": "05-11 00:10:19.851[DEBUG][http-nio-39545-exec-9] ", "fields": {

"log_topic": "app.log"

},

"host": { "name": "172.33.12.109"

}, "agent": { "id": "6a86e9d9-e1e8-4b32-b027-f1c936f66e4f", "version": "7.0.1", "name": "172.33.12.109", "type": "filebeat",

"ephemeral_id": "8326a240-e9de-44f4-b24d-a1c8d2654e19", "hostname": "client-ali"

}

}
```

![](https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/elk_10.png)

![](https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/elk_11.png)

![](https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/elk_12.png)

